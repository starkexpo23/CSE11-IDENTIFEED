{\rtf1\ansi\ansicpg1252\cocoartf2512
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fnil\fcharset0 HelveticaNeue;}
{\colortbl;\red255\green255\blue255;\red255\green255\blue255;\red16\green131\blue255;}
{\*\expandedcolortbl;;\cssrgb\c100000\c100000\c100000;\cssrgb\c0\c60000\c100000;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs26 \cf2 \cb3 \expnd0\expndtw0\kerning0
The images must be in one of the following formats: JPEG, PNG, GIF, BMP, ICO.\
Each image must be 30MB or smaller. Note that AutoML Vision Edge downscales most images during preprocessing, so there's generally no accuracy benefit to providing very high resolution images.\
Include at least 10, and preferably 100 or more, examples of each label.\
\
If your Firebase project is on the Spark plan, your project can have at most one dataset, with a maximum of 1,000 images.\
Include multiple angles, resolutions, and backgrounds for each label.\
The training data should be as close as possible to the data on which predictions are to be made. For example, if your use case involves blurry and low-resolution images (such as from a security camera), your training data should be composed of blurry, low-resolution images.\
The models generated by AutoML Vision Edge are optimized for photographs of objects in the real world. They might not work well for X-rays, hand drawings, scanned documents, receipts, and so on.\
\
Also, the models can't generally predict labels that humans can't assign. So, if a human can't assign labels by looking at the image for 1-2 seconds, the model likely can't be trained to do it either.\
\
\pard\pardeftab720\partightenfactor0
\cf2 Magbubuild ka ng Model sa firebase AutoMl using set of images and tags, yung model na yun yun na yung image recognition. Tapos kailangan mo idownload yung model na yun then copy and paste it sa assets folder ng android project. After that usable na siya, implement naman sa code.\
\
Mag iinitialize ka ng labeler which is yung model na na Build mo. Tapos ipapasa mo sakanya yung image tapos magrereturn siya ng label. Label is kung anong image yun, tapos magbibigay din siya ng confidence value, confidence value is kung gaano kalaki yung chance na tama yung na recognize niya. Then yung label na nakuha natin icrocross match natin yung sa database para makuha natin yung custom food informations. For example adobo ang label na rineturn tapos confidence label niya is 60 gagamitin natin label na yun tapos mag quequery tayo sa database para mahanap yung adobo, if meron ididisplay natin information ng adobo, if wala, ibig sabihin nun image cannot be recognized. Bale overall two steps regocnition siya, first is sa labeler model and second is sa database entity.\
}